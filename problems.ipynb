{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edaaf6bd",
   "metadata": {},
   "source": [
    "# Compute Architecure - Assessment\n",
    "**Course**: TU 2025 25-26: 8645 -- COMPUTER INFRASTRUCTURE  \n",
    "**Lecturer**: Ian McLauglin  \n",
    "**Author**: Clyde Watts  \n",
    "\n",
    "__Summary__\n",
    "\n",
    "The object of the Compute Architecture - Assessment , is to create a notebook ( problems.ipynb ) and an associated python script , which will export the FAANG share prices using yfinance for the last 5 business days and then load the files , and produce a report of the closing prices. \n",
    "\n",
    "\n",
    "\n",
    "![DataFlow](./faang_dataflow.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885352aa",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "yfinance - financial ticker data from yahoo  - [yfinance](https://github.com/ranaroussi/yfinance)\n",
    "datetime - pythons inbuild date time\n",
    "logging - python logging\n",
    "os - operating system functions\n",
    "glob - file selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pathlib as Path\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1914b",
   "metadata": {},
   "source": [
    "##  Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8318493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all CSV files in the data directory\n",
    "data_path = \"./data/\"\n",
    "files = glob.glob(os.path.join(data_path, \"*.csv\"))\n",
    "for f in files:\n",
    "    print(f\"Deleting file: {f}\")\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961327e3",
   "metadata": {},
   "source": [
    "### Helper Functions \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a17f285",
   "metadata": {},
   "source": [
    "__Function: print_status__\n",
    "\n",
    "Prints the status with a green tick or red cross. This makes it easier to validate function return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac80003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def print_status(return_code, description, return_message)-> None:\n",
    "    \"\"\"\n",
    "    Print status with visual indicator\n",
    "    \n",
    "    Args:\n",
    "        return_code (int): 0 for success, non-zero for failure\n",
    "        description (str): Status description\n",
    "        return_message (str): Related file name\n",
    "    \"\"\"\n",
    "    if return_code == 0:\n",
    "        # Green tick for success (bold)\n",
    "        status_symbol = \"\\033[1;92mâœ“\\033[0m\"  # Bold green checkmark\n",
    "    else:\n",
    "        # Red X for failure (bold)\n",
    "        status_symbol = \"\\033[1;91mâœ—\\033[0m\"  # Bold red X\n",
    "\n",
    "    # Print entire line in bold\n",
    "    print(f\"\\033[1m{status_symbol} Status: {return_code}, Message: {description}, File: {return_message}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea36a21",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Check if print status will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Smoke Test Results:\")\n",
    "print_status(0, \"Latest file retrieval\", \"file_name.csv\")\n",
    "print_status(1, \"File retrieval failed\", \"file_name.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15eaae4",
   "metadata": {},
   "source": [
    "__Function : diagnose_difference__\n",
    "\n",
    "After the lecture on loading csv , and the issue of the original and loaded csv differences. I used gemeni 3 and prompted for , _how would i compare the difference between the original dataframe and the exported and imported data frame in pandas_\n",
    "\n",
    "Note: \n",
    "\n",
    "There are alteratives to csv which do preserve the data structure , pickle or parquet. If I was implementing in production I would use parquet , or maybe invent iceberg or datalake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4ef25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_differences(df_original, df_loaded)-> None:\n",
    "    \"\"\"\n",
    "    Compares two DataFrames and prints a readable report of differences.\n",
    "    \"\"\"\n",
    "    print(\"--- DIAGNOSTIC REPORT ---\")\n",
    "    \n",
    "    # 1. Check Shape\n",
    "    if df_original.shape != df_loaded.shape:\n",
    "        print(f\"âŒ SHAPE MISMATCH: Original {df_original.shape} vs Loaded {df_loaded.shape}\")\n",
    "        return # Stop if shapes don't match\n",
    "    else:\n",
    "        print(\"âœ… Shapes match\")\n",
    "\n",
    "    # 2. Check Index\n",
    "    try:\n",
    "        pd.testing.assert_index_equal(df_original.index, df_loaded.index)\n",
    "        print(\"âœ… Indices match\")\n",
    "    except AssertionError:\n",
    "        print(\"âŒ INDEX MISMATCH: The indices are different.\")\n",
    "        print(f\"   Original type: {type(df_original.index)}\")\n",
    "        print(f\"   Loaded type:   {type(df_loaded.index)}\")\n",
    "\n",
    "    # 3. Check Column Data Types (The most common CSV failure)\n",
    "    print(\"\\n--- CHECKING DTYPES ---\")\n",
    "    mismatches = 0\n",
    "    for col in df_original.columns:\n",
    "        dtype_orig = df_original[col].dtype\n",
    "        dtype_load = df_loaded[col].dtype\n",
    "        \n",
    "        if dtype_orig != dtype_load:\n",
    "            print(f\"âš ï¸ TYPE MISMATCH in '{col}': {dtype_orig} (Original) -> {dtype_load} (Loaded)\")\n",
    "            mismatches += 1\n",
    "    \n",
    "    if mismatches == 0:\n",
    "        print(\"âœ… All data types match\")\n",
    "\n",
    "    # 4. Strict Equality Check (Values)\n",
    "    print(\"\\n--- STRICT EQUALITY ---\")\n",
    "    try:\n",
    "        # check_dtype=False allows us to see if values match even if types don't (e.g. int vs float)\n",
    "        pd.testing.assert_frame_equal(df_original, df_loaded, check_dtype=True)\n",
    "        print(\"ðŸŽ‰ SUCCESS: DataFrames are identical!\")\n",
    "    except AssertionError as e:\n",
    "        print(\"âŒ VALUE/STRICT CHECK FAILED.\")\n",
    "        print(\"   (CSV often changes float precision or converts Ints to Floats if NaNs exist)\")\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "\n",
    "# 1. Create a complex DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': pd.to_datetime(['2023-01-01', '2023-01-02']),\n",
    "    'integer': [1, 2],\n",
    "    'float': [1.123456789, 2.5],\n",
    "    'text': ['hello', 'world']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9282e41",
   "metadata": {},
   "source": [
    "__Smoke Test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b166c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. The \"Bad\" Round Trip (Standard CSV)\n",
    "df.to_csv('test.csv', index=False)\n",
    "df_loaded_csv = pd.read_csv('test.csv')\n",
    "\n",
    "# 3. Run Diagnostic\n",
    "diagnose_differences(df, df_loaded_csv)\n",
    "\n",
    "# cleanup\n",
    "os.remove('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37afff2",
   "metadata": {},
   "source": [
    "__Function: data_retention__\n",
    "\n",
    "This will cleanup data , plot and log directories old files ( older than 21 days )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_retention(old_days=21)-> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    This will cleanup data , plot and log directories old files ( older than old_days )\n",
    "    \n",
    "    Args:\n",
    "        old_days (int): Number of days to retain files. Files older than this will be deleted.\n",
    "    \"\"\"\n",
    "    return_code = 0\n",
    "    return_message = \"Data retention completed successfully.\"\n",
    "    # Define directories to clean\n",
    "    directories = [\"./data/\", \"./plots/\", \"./logs/\"]\n",
    "    # Get current date\n",
    "    now = datetime.now()\n",
    "    # Calculate cutoff date\n",
    "    cutoff_date = now - timedelta(days=old_days)\n",
    "\n",
    "    for directory in directories:\n",
    "        # Ensure directory exists\n",
    "        Path.Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "        # Iterate over files in directory\n",
    "        for file_path in Path.Path(directory).glob(\"*\"):\n",
    "            # Get file's last modified time\n",
    "            file_mod_time = datetime.fromtimestamp(file_path.stat().st_mtime)\n",
    "            # If file is older than cutoff date, delete it\n",
    "            if file_mod_time < cutoff_date:\n",
    "                print(f\"Deleting old file: {file_path} (Last modified: {file_mod_time})\")\n",
    "                file_path.unlink()  # Delete the file\n",
    "    return return_code,  return_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d0f9e",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Check if there are any plot , data and log files older 21 days and delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741df664",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_code, return_message = data_retention(old_days=21)\n",
    "print_status(return_code, \"Data Retention Cleanup\", return_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c48bb87",
   "metadata": {},
   "source": [
    "## Problem 1: Data from yfinance\n",
    "\n",
    "Using the [yfinance](https://github.com/ranaroussi/yfinance) Python package, write a function called `get_data()` that downloads all hourly data for the previous five days for the five FAANG stocks:\n",
    "\n",
    "- Facebook (META)\n",
    "- Apple (AAPL)\n",
    "- Amazon (AMZN)\n",
    "- Netflix (NFLX)\n",
    "- Google (GOOG)\n",
    "\n",
    "The function should save the data into a folder called `data` in the root of your repository using a filename with the format `YYYYMMDD-HHmmss.csv` where `YYYYMMDD` is the four-digit year (e.g. 2025), followed by the two-digit month (e.g. `09` for September), followed by the two digit day, and `HHmmss` is hour, minutes, seconds.\n",
    "Create the `data` folder if you don't already have one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68775099",
   "metadata": {},
   "source": [
    "## Problem 1: Requirements ##\n",
    "\n",
    "### Extract ###\n",
    "\n",
    "1.  Extract from yfinance data the stock data for META,AAPL,AMZN,NFLX,GOOG\n",
    "2.  For 5 complete previous days trading , we need to take into account that NASDAQ trades from Monday to Friday. If we go back 7 days we will always ignore weekends\n",
    "3.  File format will YYYYMMDD-HHmmss.csv where YYYY - is 4 digit year , MM month 01-12 , DD - is 01-31. HH - hours , 24 our clock , mm - minutes 00-59 , seconds 00-59.\n",
    "4.  Grain - Hour\n",
    "\n",
    "__Columns__\n",
    "\n",
    "- Date , <ticket> ( Open,High,Low,Close,Volume) ....\n",
    "ticket is META , AAPL , AMZN , NFLX or GOOG\n",
    "- Open - open price\n",
    "- Close - close price\n",
    "- High - High pricr\n",
    "- Low - Low price\n",
    "- Volumn - Volume in period\n",
    "\n",
    "The data frame return has an index on the date , and is a multilevel index. Level one is the ticket , and the second level is the metric - that is open , close , high , low prices and volume \n",
    "\n",
    "Note: AI was used to generate the checklist , the author likes the style. The checklist was not used as a prompt to generate the code.\n",
    "\n",
    "### Assignment: Problem 1 Requirements Specification\n",
    "\n",
    "**1. Data Specification**\n",
    "* [âœ…] Define the list of target tickers: META, AAPL, AMZN, NFLX, and GOOG.\n",
    "* [âœ…] Define the data interval as \"hourly\".\n",
    "* [âœ…] Define the data period as the \"previous five days\".\n",
    "\n",
    "**2. Data Fetching**\n",
    "* [âœ…] Use the `yfinance` Python package.\n",
    "* [âœ…] Write code to download the data for all five tickers based on the interval and period.\n",
    "* [âœ…] Store the downloaded data, likely in a `pandas` DataFrame.\n",
    "\n",
    "**3. Folder Management**\n",
    "* [âœ…] Check if a folder named `data` exists in the root of the repository.\n",
    "* [âœ…] If the `data` folder does not exist, create it.\n",
    "\n",
    "**4. File Output**\n",
    "* [âœ…] Get the current date and time.\n",
    "* [âœ…] Format the current date and time into a string `YYYYMMDD-HHmmss`.\n",
    "* [âœ…] Create the full output path by combining the `data` folder, the formatted datetime string, and the `.csv` extension.\n",
    "* [âœ…] Save the downloaded data DataFrame to this CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b24fd",
   "metadata": {},
   "source": [
    "__Global Parameters__\n",
    "\n",
    "tickers - this is a list of stocks short names of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tickers to download\n",
    "tickers = [\"META\", \"AAPL\", \"AMZN\", \"NFLX\", \"GOOG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653e2b5",
   "metadata": {},
   "source": [
    "__Function : get_data__\n",
    "\n",
    "This downloads the latest data for a number of listed stock companies using yfinance module and writes to CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea49ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data(tickers = tickers,start_date=None, end_date=None,interval=\"1h\",data_path=\"./data/\",once_only=True)-> tuple[int, str, str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Function to get stock data from yfinance\n",
    "\n",
    "    Parameters:\n",
    "    tickers (list): List of stock tickers to download data for\n",
    "    start_date (str): Start date for data in format \"YYYY-MM-DD\". If None, defaults to 6 days ago.\n",
    "    end_date (str): End date for data in format \"YYYY-MM-DD\". If None, defaults to yesterday.\n",
    "    interval (str): Data interval. Default is \"1h\".\n",
    "    data_path (str): Path to save the data. Default is \"./data/\".\n",
    "    once_only (bool): If True, download data only once for a date and do not overwrite existing files. Default is True.\n",
    "    If set to false it will delete existing files and download again.\n",
    "    TODO: add only once functionality\n",
    "    Returns:\n",
    "       return_code : 0 for success, -1 for failure\n",
    "       return_message : message indicating success or failure\n",
    "       file_name (str): Name of the file where data is saved\n",
    "    \"\"\"\n",
    "    return_code = 0\n",
    "    return_message = \"Success\"\n",
    "    file_name = None\n",
    "    df_data = None\n",
    "    # TODO : implement once_only functionality\n",
    "    # TODO : Sort out logic of start_date and end_date for once only check , simplify\n",
    "    # Get current date and time and keep it constant\n",
    "    now_dttm = datetime.now()\n",
    "    # if start_date is None , set to today - 7 days\n",
    "    start_date_dttm =(now_dttm - timedelta(days=7)) if start_date is None else datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    start_date = start_date_dttm.strftime(\"%Y-%m-%d\") if start_date is None else start_date\n",
    "    start_date_dttm = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    # create file name from start date\n",
    "    file_name = f\"{data_path}{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "    # create string for glob to check if file exists for start date\n",
    "    start_date_glob_str = f\"{data_path}{datetime.now().strftime('%Y%m%d')}*.csv\"\n",
    "    if once_only and glob.glob(start_date_glob_str):\n",
    "        logging.info(f\"File already exists for start date {start_date}, skipping download.\")\n",
    "        existing_files = glob.glob(start_date_glob_str)\n",
    "        file_name = existing_files[0]  # Get the first matching file\n",
    "        return return_code, return_message, file_name, None\n",
    "\n",
    "        \n",
    "    # if end_date is None , set to today - 0 days this means yesterday's data inclusive\n",
    "    if end_date is None:\n",
    "        end_date = (datetime.now() - timedelta(days=0)).strftime(\"%Y-%m-%d\")\n",
    "    else: # convert end_date to datetime object\n",
    "        end_date_time = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "        # add 1 day to end_date to make it inclusive\n",
    "        end_date = (end_date_time + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    # check if directory exists\n",
    "    if not os.path.exists(data_path):\n",
    "        logging.info(f\"Creating directory: {data_path}\")\n",
    "        try:\n",
    "            os.makedirs(data_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating directory: {e}\")\n",
    "            return_code = -1\n",
    "            return_message = f\"Error creating directory: {e}\"\n",
    "            return return_code, return_message, None, None\n",
    "    # get start date only string for file name for once only check\n",
    "\n",
    "    # if file exists then delete it\n",
    "    if os.path.exists(file_name):\n",
    "        logging.info(f\"Deleting existing file: {file_name}\")\n",
    "        try:\n",
    "            os.remove(file_name)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting file: {e}\")\n",
    "            return_code = -1\n",
    "            return_message = f\"Error deleting file: {e}\"\n",
    "            return return_code, return_message, None, None\n",
    "    logging.info(f\"Start Date: {start_date}, End Date: {end_date}\")\n",
    "    try:\n",
    "        df_data = yf.download(tickers, interval=interval, group_by='ticker',start=start_date, end=end_date,auto_adjust=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading data: {e}\")\n",
    "        return_code = -1\n",
    "        return_message = f\"Error downloading data: {e}\"\n",
    "        return return_code, return_message, None, None\n",
    "    # Save the data to a CSV file\n",
    "    df_data.to_csv(file_name)\n",
    "    return return_code, return_message, file_name,df_data\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a422e",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Validate that the function does not abend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting data download...\")\n",
    "return_code, return_message, file_name , df_data = get_data(tickers=tickers,once_only=False)\n",
    "print_status(return_code, return_message, file_name)\n",
    "# check if file exists\n",
    "if return_code == 0 and file_name is not None and os.path.exists(file_name):\n",
    "    print_status(0,f\"Data downloaded and saved to {file_name}\", file_name)\n",
    "else:\n",
    "    print_status(-1,\"Data download failed.\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf925c5",
   "metadata": {},
   "source": [
    "## Problem 2: Plotting Data\n",
    "\n",
    "Write a function called `plot_data()` that opens the latest data file in the `data` folder and, on one plot, plots the `Close` prices for each of the five stocks.\n",
    "The plot should include axis labels, a legend, and the date as a title.\n",
    "The function should save the plot into a `plots` folder in the root of your repository using a filename in the format `YYYYMMDD-HHmmss.png`.\n",
    "Create the `plots` folder if you don't already have one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe156c9c",
   "metadata": {},
   "source": [
    "\n",
    "### Assignment: Problem 2 Requirements Specification\n",
    "\n",
    "Here is a checklist of all the tasks the `plot_data()` function must accomplish:\n",
    "\n",
    "**1. File Input & Data Loading**\n",
    "* [âœ…] Access the `data` folder.\n",
    "* [âœ…] Identify the *latest* file in the `data` folder (e.g., by checking file modification time or finding the most recent date in the filename).\n",
    "* [âœ…] Open and read the data from this file (assuming it's a format like CSV, likely using `pandas`).\n",
    "\n",
    "**2. Data Processing**\n",
    "* [âœ…] Extract the `Close` price columns for all five stocks.\n",
    "* [âœ…] Ensure the corresponding date/time data is available to be used for the x-axis.\n",
    "\n",
    "**3. Plot Generation & Styling**\n",
    "* [âœ…] Create a *single* plot figure.\n",
    "* [âœ…] Plot all five `Close` price series as lines on this single plot.\n",
    "* [âœ…] Set a clear label for the x-axis (e.g., \"Date\").\n",
    "* [âœ…] Set a clear label for the y-axis (e.g., \"Closing Price ($)\").\n",
    "* [âœ…] Add a legend that correctly identifies each of the five stocks.\n",
    "* [âœ…] Get the *current* date and time.\n",
    "* [âœ…] Set the plot's title to the current date (e.g., \"Stock Prices as of YYYY-MM-DD\").\n",
    "\n",
    "**4. File Output**\n",
    "* [âœ…] Check if a folder named `plots` exists in the root directory.\n",
    "* [âœ…] If the `plots` folder does not exist, create it.\n",
    "* [âœ…] Generate a filename based on the current date and time in `YYYYMMDD-HHmmss` format (e.g., `20251109-161120`).\n",
    "* [âœ…] Save the generated plot to the `plots` folder using the generated filename with a `.png` extension.\n",
    "* [âœ…] Ensure the plot is closed after saving to free up resources.\n",
    "\n",
    "\n",
    "\n",
    "[glob function](https://docs.python.org/3/library/glob.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adeeffe",
   "metadata": {},
   "source": [
    "__Function : get_the_latest_file__\n",
    "\n",
    "This scans directory ./data ( parameter ) using a pattern 20....csv to get the latest file and returns the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Function to get the latest file from a directory\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def get_latest_file(data_path=\"./data/\")-> tuple[int, str, str]:\n",
    "    \"\"\"\n",
    "    Returns the path to the latest data file in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the directory containing the data files.\n",
    "\n",
    "        tuple: (return_code, return_message, latest_file) where latest_file is the path to the latest data file, or None if no files are found.\n",
    "        str: The path to the latest data file, or None if no files are found.\n",
    "    \"\"\"\n",
    "    return_code = 0\n",
    "    return_message = \"Success\"\n",
    "    latest_file = None\n",
    "\n",
    "    logging.info(f\"Getting the latest file from {data_path}\")\n",
    "    # File pattern\n",
    "    file_pattern = \"20[0-9][0-9][0-1][0-9][0-3][0-9]_[0-9][0-9][0-9][0-9][0-9][0-9].csv\"\n",
    "    # Add path to file pattern\n",
    "    file_pattern = os.path.join(data_path, file_pattern)\n",
    "    # glob searches directories for files based on a pattern\n",
    "    try:\n",
    "        list_of_files = glob.glob(file_pattern)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred while searching for files: {e}\")\n",
    "        return_code=-1\n",
    "        return_message=f\"Error occurred while searching for files: {e}\"\n",
    "        return return_code, return_message, None\n",
    "    if not list_of_files:\n",
    "        logging.warning(f\"No files found in {data_path} matching pattern {file_pattern}\")\n",
    "        return_code = -1\n",
    "        return_message = f\"No files found in {data_path} matching pattern {file_pattern}\"\n",
    "        return return_code, return_message, None\n",
    "    # find the latest file based on creation time\n",
    "    #    max parameters - list and function which gets \"value\" associated with each item in the list\n",
    "    #    this gets the \"youngest\" file based on creation time \n",
    "    #    not necessarily the latest date in the file name - design decision \n",
    "    #    the premise is that the latest file created is the one we want to use\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    logging.info(f\"Latest file: {latest_file}\")\n",
    "    return return_code, return_message, latest_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b031a3",
   "metadata": {},
   "source": [
    "__Function: get_PNG_filename_from_CSV_filename__\n",
    "\n",
    "This function will return the png file name based on csv file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df98f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PNG_filename_from_CSV_filename(csv_filename,plot_path=\"./plots/\")-> tuple[int, str, str]:\n",
    "    \"\"\"\n",
    "    Function to get PNG filename from CSV filename\n",
    "\n",
    "    Parameters:\n",
    "    csv_filename (str): Name of the CSV file\n",
    "    plot_path (str): Path to save the PNG file. Default is \"./plots/\".\n",
    "\n",
    "    Returns:\n",
    "       png_filename (str): Name of the PNG file\n",
    "    \"\"\"\n",
    "    return_code = 0\n",
    "    return_message = \"Success\"\n",
    "    # extract base name from csv_filename\n",
    "    base_name = os.path.basename(csv_filename)\n",
    "    # remove .csv extension\n",
    "    base_name = os.path.splitext(base_name)[0]\n",
    "    # create png filename\n",
    "    png_filename = f\"{plot_path}{base_name}.png\"\n",
    "    return return_code, return_message, png_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1786fdb",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Run both functions , get_lastest_file and convert name from CSV to PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_code, return_message, file_name = get_latest_file()\n",
    "print_status(return_code, f\"Latest file retrieval - Return Code: {return_code}, Message: {return_message}, File: {file_name}\", return_message)\n",
    "# now get png file name from csv file name\n",
    "return_code, return_message, png_file_name = get_PNG_filename_from_CSV_filename(file_name, \"./plots/\")\n",
    "print_status(return_code, f\"PNG file path retrieval - Return Code: {return_code}, Message: {return_message}, File: {png_file_name}\", return_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08641d68",
   "metadata": {},
   "source": [
    "__Function : load_file_into_dataframe__\n",
    "\n",
    "This loads the file name into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff18c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_into_dataframe(file)-> tuple[int, str, pd.DataFrame]:\n",
    "    \"\"\"load_file_into_dataframe\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the data file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (return_code, return_message, df) where:\n",
    "            return_code (int): 0 for success, -1 for failure\n",
    "            return_message (str): Success or error message\n",
    "            df (pd.DataFrame): The data as a pandas DataFrame with multi-level columns\n",
    "    \"\"\"\n",
    "    return_code = 0\n",
    "    return_message = \"Success\"\n",
    "    df = None\n",
    "    \n",
    "    # Check if file name is provided\n",
    "    if file is None:\n",
    "        logging.error(\"No file provided to load into dataframe.\")\n",
    "        return_code = -1\n",
    "        return_message = \"No file provided to load into dataframe.\"\n",
    "        return return_code, return_message, None\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file):\n",
    "        logging.error(f\"File does not exist: {file}\")\n",
    "        return_code = -1\n",
    "        return_message = f\"File does not exist: {file}\"\n",
    "        return return_code, return_message, None\n",
    "    \n",
    "    # Load the CSV file into a DataFrame with multi-level columns\n",
    "    try:\n",
    "        df = pd.read_csv(file, header=[0,1], index_col=0, parse_dates=True)\n",
    "        logging.info(f\"Successfully loaded data from {file}. Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading file {file}: {e}\")\n",
    "        return_code = -1\n",
    "        return_message = f\"Error loading file {file}: {e}\"\n",
    "        return return_code, return_message, None\n",
    "    \n",
    "    return return_code, return_message, df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c04f5b",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Check the following\n",
    "\n",
    "1. Get the latest file\n",
    "2. Load latest file into data frame\n",
    "3. Convert CSV file name into PNG file name\n",
    "4. Print Shape\n",
    "5. Validate Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file data before loading from csv\n",
    "print(\"Get file data before loading from csv...\")\n",
    "return_code,return_message,before_file_name,df_before = get_data(tickers=tickers, once_only=False)\n",
    "print_status(return_code, f\"Data download before load - Return Code: {return_code}, Message: {return_message}\", None)\n",
    "print(\"Loading data from the latest file...\")\n",
    "return_code, return_message, latest_file = get_latest_file()\n",
    "full_file_name = os.path.abspath(latest_file)\n",
    "print(f\"Loading data from file: {full_file_name}\")\n",
    "print_status(return_code, f\"Latest file retrieval - Return Code: {return_code}, Message: {return_message}, File: {latest_file}\", return_message)    \n",
    "print(\"Loading file into dataframe...\")\n",
    "return_code, return_message, df = load_file_into_dataframe(latest_file)\n",
    "print_status(return_code, f\"File load - Return Code: {return_code}, Message: {return_message}, File: {latest_file}\", return_message)    \n",
    "\n",
    "print(f\"Dataframe shape: {df.shape}\")\n",
    "# convert csv file name to png file name\n",
    "return_code, return_message, png_file_path = get_PNG_filename_from_CSV_filename(latest_file, \"./plots/\")\n",
    "print(f\"PNG file path: {png_file_path}\")\n",
    "# calibrate structures , before and after loading from csv\n",
    "diagnose_differences(df_before, df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb50f8e",
   "metadata": {},
   "source": [
    "### Investigate Data Frame\n",
    "\n",
    "Have a look at the dataframe and see it's structure. \n",
    "\n",
    "https://ranaroussi.github.io/yfinance/reference/api/yfinance.download.html#yfinance.download\n",
    "\n",
    "The index is DatetimeIndex - that is the timestamp of the price.\n",
    "The data appears Company/Ticker - and then metrics - open,high,low,close,volume\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the index and columns\n",
    "print(\" Data Frame Info\")\n",
    "print(df.info(verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82d3b4",
   "metadata": {},
   "source": [
    "Check the first and last dates . To check if the week is being covered.\n",
    "That is the fense post problem.\n",
    "\n",
    "_Note:_ The code is not catering for bank holiday - I was caught out for thanks giving day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the datetime index and convert to a list\n",
    "datetime_index = df.index.to_series().reset_index(drop=True)\n",
    "# Convert series datetime to dates and remove duplicates and sort\n",
    "date_list = datetime_index.dt.date.drop_duplicates().sort_values().astype(str)\n",
    "# the date list should include 5 trading days for hourly data over a week\n",
    "print(\"Trading Dates in Data:\")\n",
    "print(date_list)\n",
    "if len(date_list) != 5:\n",
    "    print_status(-1, \"Unexpected number of trading days\", f\"Expected 5 trading days, but got {len(date_list)} days.\")\n",
    "    print(f\"Warning: Expected 5 trading days, but got {len(date_list)} days.\")\n",
    "else:\n",
    "    print_status(0, \"Correct number of trading days\", f\"Got {len(date_list)} trading days as expected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48881ec",
   "metadata": {},
   "source": [
    "Investigate the time zones , the data is from US NASDAQ - Monday to Friday 9:30 to 21:30 EST , UTC+8\n",
    "\n",
    "https://www.ig.com/en/trading-strategies/nasdaq-opening-and-closing-times--when-can-you-trade--230527#:~:text=The%20index%20opens%20at%209.30,that's%204%20am%20UTC%2B8.&text=However%2C%20you%20can%20trade%20the,a%20day%2C%20Monday%20to%20Thursday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only get the datetime index and convert to a list\n",
    "datetime_index = df.index.to_series().reset_index(drop=True)\n",
    "# Extract the time zone info\n",
    "time_zone = datetime_index.dt.tz\n",
    "print(f\"Time Zone Info: {time_zone}\")\n",
    "# Extract time from datetime index\n",
    "time_list = datetime_index.dt.time.drop_duplicates().sort_values().astype(str)\n",
    "print(\"Time List:\")\n",
    "print(time_list)\n",
    "# see if the convert the timezone to EST for NASDAQ data is possible\n",
    "datetime_index_est = datetime_index.dt.tz_convert('US/Eastern')\n",
    "print(\"Datetime Index in EST:\")\n",
    "time_list_est = datetime_index_est.dt.time.drop_duplicates().sort_values().astype(str)\n",
    "print(\"Time List in EST:\")\n",
    "print(time_list_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce3337",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data from the latest file...\")\n",
    "return_code, return_message, latest_file = get_latest_file()\n",
    "print_status(return_code, f\"Latest file retrieval - Return Code: {return_code}, Message: {return_message}, File: {latest_file}\", return_message)    \n",
    "\n",
    "return_code, return_message, df = load_file_into_dataframe(latest_file)\n",
    "print_status(return_code, f\"File load - Return Code: {return_code}, Message: {return_message}, File: {latest_file}\", return_message)    \n",
    "\n",
    "print(df.shape)\n",
    "# convert csv file name to png file name\n",
    "return_code, return_message, png_file_path = get_PNG_filename_from_CSV_filename(latest_file, \"./plots/\")\n",
    "print(f\"PNG file path: {png_file_path}\")\n",
    "return_code, return_message, df = load_file_into_dataframe(latest_file)\n",
    "print(f\"Function :  Return_Code = {return_code} Return Message = {return_message}\")\n",
    "data_path = \"./data/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e873bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17625af6",
   "metadata": {},
   "source": [
    "__Function : plot_data__\n",
    "\n",
    "\n",
    "[set_major_locator](https://matplotlib.org/stable/api/_as_gen/matplotlib.axis.Axis.set_major_locator.html)\n",
    "[set_major_formater](https://matplotlib.org/stable/api/_as_gen/matplotlib.axis.Axis.set_major_formatter.html)\n",
    "[plotly mdates](https://matplotlib.org/stable/api/dates_api.html)\n",
    "\n",
    "Gemini prompt : How do I plot unsign matplotlib a x-axis timeseries , where i can format the date time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(show_plot=False,bpi=300)-> tuple[int, str, str]:\n",
    "    \"\"\"plot_data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The data as a pandas DataFrame.\n",
    "        png_file_path (str): The path to save the plot image.\n",
    "        bpi (int): The resolution (bits per inch) for the saved plot image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    return_code = 0\n",
    "    return_message = \"Success\"\n",
    "    png_file_name = None\n",
    "    # define date format string YYYY-MM-DD HH\n",
    "    # date_format_str = \"%m-%d %H\" # Removed\n",
    "    # create date formatter\n",
    "    # date_formatter = plt.matplotlib.dates.DateFormatter(date_format_str) # Removed\n",
    "    logging.info(\"Starting data plotting...\")\n",
    "    # Get the latest file\n",
    "    return_code, return_message, png_file_name = get_latest_file()\n",
    "    if return_code != 0:\n",
    "        logging.error(f\"Latest file retrieval failed - Return Code: {return_code}, Message: {return_message}\")\n",
    "        return return_code, return_message, png_file_name\n",
    "    # load data into dataframe\n",
    "    return_code, return_message, df_raw = load_file_into_dataframe(png_file_name)\n",
    "    if return_code != 0:\n",
    "        logging.error(f\"File load failed - Return Code: {return_code}, Message: {return_message}, File: {png_file_name}\")\n",
    "        return return_code, return_message, png_file_name\n",
    "    # convert csv file name to png file name\n",
    "    return_code, return_message, png_file_name = get_PNG_filename_from_CSV_filename(png_file_name, \"./plots/\")\n",
    "    if return_code != 0:\n",
    "        logging.error(f\"PNG file path retrieval failed - Return Code: {return_code}, Message: {return_message}, File: {png_file_path}\")\n",
    "        return return_code, return_message, png_file_name\n",
    "    # Create plots directory if it doesn't exist\n",
    "    # extract path from png_file_name\n",
    "    png_path = Path.Path(png_file_name).parent \n",
    "    try:\n",
    "        os.makedirs(png_path, exist_ok=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create directory {png_path} - {e}\")\n",
    "        return 1, f\"Failed to create directory {png_path}\", None\n",
    "    # copy dataframe to avoid modifying original\n",
    "    df = df_raw.copy()\n",
    "    # Convert index to EST timezone and extract date - NASDAQ data is in EST\n",
    "    df['Datetime_EST'] = df.index.tz_convert('US/Eastern')\n",
    "    # Extract date from datetime\n",
    "    df['Date'] = df['Datetime_EST'].dt.date\n",
    "    # Get start and end dates for title\n",
    "    start_date = df['Date'].min()\n",
    "    end_date = df['Date'].max()\n",
    "    logging.info(f\"Data covers from {start_date} to {end_date}\")\n",
    "    # ---- Plotting ----\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle(\"FAANG Stock Reports\", fontsize=16)\n",
    "    # Define tickers globally or pass as parameter\n",
    "    if df is None or png_path is None:\n",
    "        logging.error(\"DataFrame or PNG file path is None.\")\n",
    "        return\n",
    "    #print(date_list)\n",
    "    fig.set_size_inches(14, 8)\n",
    "    for ticker in tickers:\n",
    "        ax.plot(df['Datetime_EST'], df[(ticker, 'Close')], label=ticker, linestyle='-', marker='o')\n",
    "\n",
    "\n",
    "    # set date ticks to 90-degree rotation for readability\n",
    "    # plt.xticks(rotation=90) # Removed - Handled by autofmt_xdate\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5) # Updated grid\n",
    "    ax.set_xlabel(' Trading Date and Time ', fontsize=12)\n",
    "    ax.set_ylabel('Close Price in $', fontsize=12)\n",
    "    ax.set_title(f'FAANG Stock Closing Price  From {start_date} to {end_date}', fontsize=14)\n",
    "    leg = ax.legend(loc='upper left', fontsize=10, bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "    leg.get_title().set_fontsize(11)\n",
    "    leg.set_title('Tickers')\n",
    "    \n",
    "    # Split date time into major and minor ticks\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "    # Minor Ticks: Hours (HHh)\n",
    "    # Show hours 0, 6, 12, 18. Adjust 'byhour' as needed.\n",
    "    ax.xaxis.set_minor_locator(mdates.HourLocator(byhour=[0, 6, 12, 18]))\n",
    "    ax.xaxis.set_minor_formatter(mdates.DateFormatter('%Hh'))\n",
    "    \n",
    "    # Rotate major labels for readability\n",
    "    fig.autofmt_xdate(which='major', rotation=90)\n",
    "    fig.autofmt_xdate(which='minor', rotation=90)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_file_name, dpi=bpi)\n",
    "    if show_plot:\n",
    "        plt.show()\n",
    "\n",
    "    logging.info(f\"Plot saved to {png_file_name}\")\n",
    "    plt.close(fig)\n",
    "    return return_code, return_message, png_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1eb4ce",
   "metadata": {},
   "source": [
    "__Smoke Test__\n",
    "\n",
    "Validate that the plot_data function works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9349120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Smoke Test : Plotting\")\n",
    "return_code,return_message,filename = plot_data(show_plot=True)\n",
    "print_status(return_code, f\"Plotting - Return Code: {return_code}, Message: {return_message}, File: {filename}\", return_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03892de6",
   "metadata": {},
   "source": [
    "# Problem 3: Script #\n",
    "Create a Python script called faang.py in the root of your repository. Copy the above functions into it and it so that whenever someone at the terminal types ./faang.py, the script runs, downloading the data and creating the plot. Note that this will require a shebang line and the script to be marked executable. Explain the steps you took in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0bb424",
   "metadata": {},
   "source": [
    "## Assignment: Problem 3 Requirements Specification##\n",
    "\n",
    "\n",
    "**1. Script File Setup**\n",
    "\n",
    "* [âœ…] Create a new file named faang.py.\n",
    "\n",
    "* [âœ…] Ensure the file is saved in the root directory of the repository.\n",
    "\n",
    "**2. Script Content & Structure**\n",
    "\n",
    "* [âœ…] Add a \"shebang\" line at the very top (e.g., #!/usr/bin/env python3).\n",
    "\n",
    "* [âœ…] Include all necessary import statements at the top (for yfinance, pandas, matplotlib, os, sys, etc.).\n",
    "\n",
    "* [âœ…] Copy the get_data() function (from Problem 1) into the script.\n",
    "\n",
    "* [âœ…] Copy the plot_data() function (from Problem 2) into the script.\n",
    "\n",
    "* [âœ…] Include any helper functions needed by get_data or plot_data (like get_latest_file).\n",
    "\n",
    "* [âœ…] Create a main() function to control the script's execution.\n",
    "\n",
    "* [âœ…] Add the if __name__ == \"__main__\": block at the bottom to call the main() function.\n",
    "\n",
    "**3. Script Execution Logic**\n",
    "\n",
    "* [âœ…] Inside main(), ensure that get_data() is called first.\n",
    "\n",
    "* [âœ…] Inside main(), ensure that plot_data() is called after get_data() successfully completes.\n",
    "\n",
    "* [âœ…] Add error handling to stop the script if get_data() fails.\n",
    "\n",
    "**4. Permissions & Running**\n",
    "\n",
    "* [ ] The script must be made \"executable\" (using the chmod +x faang.py command in the terminal).\n",
    "\n",
    "* [ ] The script must run successfully from the terminal when the user types ./faang.py.\n",
    "\n",
    "**5. Documentation (Meta-Task)**\n",
    "\n",
    "* [ ] Provide a separate explanation (e.g., in the notebook) detailing the steps taken to create the script, what the shebang line does, and how to make the script executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f626ad3",
   "metadata": {},
   "source": [
    "# Smoke Test\n",
    "\n",
    "Import the \"faang.py\" module , and run the get_data() and plot_data() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ce788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faang as faang\n",
    "# Smoke Test\n",
    "# Import the \"faang.py\" module , and run the get_data() and plot_data() functions\n",
    "return_code, return_message, file_name, df_data = faang.get_data()\n",
    "print_status(return_code, f\"Data Retrieval - Return Code: {return_code}, Message: {return_message}, File: {file_name}\", return_message)\n",
    "return_code, return_message, png_file_name = faang.plot_data(show_plot=True)\n",
    "print_status(return_code, f\"Plotting - Return Code: {return_code}, Message: {return_message}, File: {png_file_name}\", return_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e4285",
   "metadata": {},
   "source": [
    "__The End__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
